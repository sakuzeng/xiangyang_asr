import os
import json

# ================= é…ç½®åŒºåŸŸ =================

# è„šæœ¬æ‰€åœ¨ç›®å½• (dataset)
BASE_DIR = os.path.dirname(os.path.abspath(__file__))

# è¾“å…¥è·¯å¾„
AISHELL_ROOT = os.path.join(BASE_DIR, "speech_asr_aishell1_testsets")
WAV_ROOT = os.path.join(AISHELL_ROOT, "wav")
TRANSCRIPT_FILE = os.path.join(AISHELL_ROOT, "transcript", "data.text")

# è¾“å‡ºæ–‡ä»¶
OUTPUT_JSONL = os.path.join(BASE_DIR, "data", "aishell_train.jsonl")

# Docker è·¯å¾„æ˜ å°„é…ç½®
# å¦‚æœæ‚¨æ˜¯åœ¨ Docker ä¸­è¿è¡Œè®­ç»ƒï¼Œéœ€è¦å°† Windows è·¯å¾„è½¬æ¢ä¸ºå®¹å™¨å†…è·¯å¾„
# æ ¹æ®æ‚¨ä¹‹å‰çš„ train.jsonlï¼Œæ˜ å°„å…³ç³»å¦‚ä¸‹ï¼š
# Windows: ...\workspace\asr\dataset
# Docker:  /home/devuser/workspace/asr/dataset
DOCKER_PREFIX = "/home/devuser/workspace/asr/dataset"

def generate_jsonl():
    print("ğŸš€ å¼€å§‹ç”Ÿæˆ AISHELL-1 è®­ç»ƒç´¢å¼•æ–‡ä»¶...")
    
    # 1. è¯»å–æ ‡æ³¨æ–‡ä»¶
    print(f"ğŸ“– è¯»å–æ ‡æ³¨æ–‡ä»¶: {TRANSCRIPT_FILE}")
    id_to_text = {}
    
    if not os.path.exists(TRANSCRIPT_FILE):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ ‡æ³¨æ–‡ä»¶ {TRANSCRIPT_FILE}")
        return

    with open(TRANSCRIPT_FILE, "r", encoding="utf-8") as f:
        for line in f:
            # æ ¼å¼: BAC009S0002W0122 è€Œå¯¹æ¥¼å¸‚æˆäº¤æŠ‘åˆ¶ä½œç”¨æœ€å¤§çš„é™è´­
            parts = line.strip().split(maxsplit=1)
            if len(parts) == 2:
                file_id, text = parts
                # å»é™¤ç©ºæ ¼ (ä¸­æ–‡ ASR é€šå¸¸ä¸éœ€è¦å­—ä¹‹é—´çš„ç©ºæ ¼)
                id_to_text[file_id] = text.replace(" ", "")

    print(f"âœ… åŠ è½½äº† {len(id_to_text)} æ¡æ ‡æ³¨æ•°æ®")

    # 2. éå†éŸ³é¢‘æ–‡ä»¶
    print(f"ğŸ” æ‰«æéŸ³é¢‘æ–‡ä»¶ç›®å½•: {WAV_ROOT}")
    jsonl_data = []
    valid_count = 0
    missing_count = 0
    
    for root, dirs, files in os.walk(WAV_ROOT):
        for file in files:
            if file.lower().endswith(".wav"):
                # è·å–æ–‡ä»¶åä½œä¸º ID (ä¾‹å¦‚: BAC009S0724W0121)
                file_id = os.path.splitext(file)[0]
                
                if file_id in id_to_text:
                    # è·å– Windows ç»å¯¹è·¯å¾„
                    abs_path = os.path.abspath(os.path.join(root, file))
                    
                    # === è·¯å¾„è½¬æ¢é€»è¾‘ ===
                    # è®¡ç®—ç›¸å¯¹äº dataset ç›®å½•çš„ç›¸å¯¹è·¯å¾„
                    # ä¾‹å¦‚: speech_asr_aishell1_testsets\wav\dev\S0724\BAC009S0724W0121.wav
                    rel_path = os.path.relpath(abs_path, BASE_DIR)
                    
                    # è½¬æ¢ä¸º Linux é£æ ¼è·¯å¾„ (å°† \ æ›¿æ¢ä¸º /)
                    rel_path_linux = rel_path.replace("\\", "/")
                    
                    # æ‹¼æ¥ Docker å‰ç¼€
                    final_path = f"{DOCKER_PREFIX}/{rel_path_linux}"
                    
                    entry = {
                        "key": file_id,
                        "wav": final_path,
                        "txt": id_to_text[file_id]
                    }
                    jsonl_data.append(entry)
                    valid_count += 1
                else:
                    # å¦‚æœæ‰¾ä¸åˆ°å¯¹åº”çš„æ ‡æ³¨ï¼Œè®°å½•ä¸€ä¸‹ï¼ˆå¯é€‰ï¼‰
                    # print(f"âš ï¸ è­¦å‘Š: æ‰¾ä¸åˆ° ID {file_id} çš„æ ‡æ³¨")
                    missing_count += 1

    # 3. å†™å…¥ JSONL æ–‡ä»¶
    os.makedirs(os.path.dirname(OUTPUT_JSONL), exist_ok=True)
    print(f"ğŸ’¾ æ­£åœ¨å†™å…¥æ•°æ®åˆ°: {OUTPUT_JSONL}")
    
    with open(OUTPUT_JSONL, "w", encoding="utf-8") as f:
        for entry in jsonl_data:
            f.write(json.dumps(entry, ensure_ascii=False) + "\n")

    print("\n" + "="*30)
    print(f"ğŸ‰ å…¨éƒ¨å®Œæˆï¼")
    print(f"ğŸ“Š æˆåŠŸåŒ¹é…å¹¶å†™å…¥: {valid_count} æ¡")
    if missing_count > 0:
        print(f"âš ï¸ æœªæ‰¾åˆ°æ ‡æ³¨çš„éŸ³é¢‘: {missing_count} æ¡")
    print(f"ğŸ“‚ è¾“å‡ºæ–‡ä»¶: {OUTPUT_JSONL}")
    print(f"â„¹ï¸  æ³¨æ„: ç”Ÿæˆçš„è·¯å¾„å·²è½¬æ¢ä¸º Docker æ ¼å¼ ({DOCKER_PREFIX}/...)")

if __name__ == "__main__":
    generate_jsonl()