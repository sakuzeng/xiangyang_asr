#!/bin/bash

workspace=`pwd`

# ã€ä¿®æ”¹ç‚¹1ã€‘å¯ç”¨å•å¡
export CUDA_VISIBLE_DEVICES="0"
gpu_num=1

# è·¯å¾„é…ç½®
data_root="/home/devuser/workspace/asr/dataset/grid_device_finetune/audio_data"
train_data="${data_root}/train.jsonl"
val_data="${data_root}/val.jsonl"

# ã€å…³é”®é…ç½®1ã€‘model_dir ä¿æŒæŒ‡å‘åŽŸå§‹åº•æ¨¡ï¼ˆä¸ºäº†åŠ è½½ tokenizer å’Œé…ç½®æ–‡ä»¶ï¼‰
model_dir="/home/devuser/.cache/modelscope/models/iic/SenseVoiceSmall"

# ã€å…³é”®é…ç½®2ã€‘æ–°å¢ž init_paramï¼ŒæŒ‡å‘ v2 è®­ç»ƒå‡ºçš„æœ€ä½³æƒé‡
# æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨äº†ä½  ls å‘½ä»¤ä¸­æ˜¾ç¤ºçš„è·¯å¾„ï¼Œè¯·ç¡®ä¿è·¯å¾„å®Œå…¨æ­£ç¡®
init_param="/home/devuser/workspace/asr/FunASR-main/examples/industrial_data_pretraining/sense_voice/outputs/sensevoice_finetune_v2/model.pt.best"

# è¾“å‡ºç›®å½•æ”¹ä¸º v3
output_dir="./outputs/sensevoice_finetune_v3"
mkdir -p ${output_dir}
log_file="${output_dir}/log_ddp.txt"

# åˆ†å¸ƒå¼å‚æ•°
DISTRIBUTED_ARGS="
    --nnodes 1 \
    --nproc_per_node $gpu_num \
    --node_rank 0 \
    --master_addr 127.0.0.1 \
    --master_port 26669
"

echo "ðŸš€ å¯åŠ¨å•å¡è®­ç»ƒ (DDP) - åŸºäºŽ v2 æƒé‡ç»§ç»­å¾®è°ƒ..."
echo "ðŸ“¦ åŸºç¡€é…ç½®: ${model_dir}"
echo "ðŸ“¦ åŠ è½½æƒé‡: ${init_param}"

torchrun $DISTRIBUTED_ARGS \
../../../funasr/bin/train_ds.py \
++model="${model_dir}" \
++init_param="${init_param}" \
++train_data_set_list="${train_data}" \
++valid_data_set_list="${val_data}" \
\
++dataset="SenseVoiceCTCDataset" \
++dataset_conf.data_names='[source,target,text_language,emo_target,event_target,with_or_wo_itn]' \
\
++dataset_conf.max_source_length=500000 \
++dataset_conf.min_source_length=1 \
++dataset_conf.max_token_length=2000 \
++dataset_conf.min_token_length=1 \
\
++dataset_conf.batch_sampler="BatchSampler" \
++dataset_conf.batch_size=30000 \
++dataset_conf.batch_type="token" \
++train_conf.accum_grad=4 \
++train_conf.grad_clip=1.0 \
++dataset_conf.num_workers=4 \
\
++train_conf.max_epoch=20 \
++train_conf.log_interval=1 \
++train_conf.resume=false \
++train_conf.validate_interval=200 \
++train_conf.save_checkpoint_interval=1000 \
\
++train_conf.val_best_metric="loss" \
++train_conf.val_metric_mode="min" \
++train_conf.keep_nbest_models=10 \
++train_conf.keep_latest_models=10 \
++train_conf.avg_nbest_model=10 \
++train_conf.use_deepspeed=false \
++optim_conf.lr=0.00005 \
++output_dir="${output_dir}" 2>&1 | tee ${log_file}